llm_provider: hybrid

groq:
  model: llama-3.3-70b-versatile
llm:
  provider: groq  
  model_name: llama-3.1-8b-instant  
  temperature: 0.1 
  max_tokens: 1024 

embeddings:
  model: all-MiniLM-L6-v2

chunking:
  chunk_size: 500
  chunk_overlap: 50

retrieval:
  top_k: 3
  

paths:
  data_dirs:
    - ./backend/data_fast
  vector_store: ./vector_store_clean

auto_load: true
